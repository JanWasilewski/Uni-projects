{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding puntuation algorythms - NLP project\n",
    "### Jan Wasilewski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I think therefore i am.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The most basic algorythm\n",
    "def addPunctuationBasic(string):\n",
    "    return string.capitalize() + '.'\n",
    "\n",
    "#Example\n",
    "addPunctuationBasic('i think therefore i am')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S', 1), ('S', 2), ('S', 3), ('I', 4)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = ['.',',',';',':','?','!']\n",
    "\n",
    "def token(string):\n",
    "    for char in chars:\n",
    "        string = string.replace(char, ' ' + char)\n",
    "    token_string = string.split()\n",
    "    return token_string\n",
    "\n",
    "def verifyPuntuation(string_check, string_test):\n",
    "    errors = []\n",
    "    j = 0\n",
    "    i = 0\n",
    "    token_check = token(string_check)\n",
    "    token_test = token(string_test)\n",
    "    while i < len(token_test) and j < len(token_check) :\n",
    "        if token_test[i] == token_check[j]:\n",
    "            i+=1\n",
    "            j+=1\n",
    "        elif token_test[i] in chars and not token_check[j] in chars:\n",
    "            errors.append(('I', i))\n",
    "            i+=1\n",
    "        elif not token_test[i] in chars and token_check[j] in chars:\n",
    "            errors.append(('D', i))\n",
    "            j+=1\n",
    "        else:\n",
    "            errors.append(('S', i))\n",
    "            i+=1\n",
    "            j+=1 \n",
    "    return errors\n",
    "\n",
    "# Example from email:\n",
    "verifyPuntuation(\"Hello. What's your name?\", \"Hello, what's Your, name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/jan/Documents/Uni/erasmus/PLN-MULCIA-Junio-2020-Dataset\")\n",
    "\n",
    "\n",
    "strings_plain = pd.read_csv(\"PunctuationTask_test.txt\", header=None)\n",
    "\n",
    "strings_check = pd.read_csv(\"PunctuationTask_check.txt\", header=None, sep = \"/n\")\n",
    "\n",
    "strings_plain = np.reshape(strings_plain.values, -1)\n",
    "strings_check = np.reshape(strings_check.values, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def getPuntuation(string):\n",
    "    split = string.split()\n",
    "    result = np.full(len(split), ' ')\n",
    "    for (index, word) in enumerate(split):\n",
    "        for char in chars:\n",
    "            if char in word:\n",
    "                result[index] = char\n",
    "                break\n",
    "    return result\n",
    "\n",
    "def verifyPuntuationMetrics(strings_plain, strings_check, model):\n",
    "    strings_predict = [model(string_plain) for string_plain in strings_plain]\n",
    "    pred = np.array([getPuntuation(string) for string in strings_predict])\n",
    "    original = np.array([getPuntuation(string) for string in strings_check])\n",
    "    index = np.where(np.array([len(v) for v in pred]) == np.array([len(v) for v in original]))[0]\n",
    "    pred_trunc = pred[index]\n",
    "    original_trunc = original[index]\n",
    "    return classification_report(np.concatenate(original_trunc), np.concatenate(pred_trunc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelBasicMetrices(strings_plain, strings_check):\n",
    "    return verifyPuntuationMetrics(strings_plain, strings_check, addPunctuationBasic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.89      1.00      0.94      1340\n",
      "           !       0.00      0.00      0.00         2\n",
      "           ,       0.00      0.00      0.00        95\n",
      "           .       0.97      0.54      0.69       106\n",
      "           :       0.00      0.00      0.00        10\n",
      "           ?       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.90      1557\n",
      "   macro avg       0.31      0.26      0.27      1557\n",
      "weighted avg       0.84      0.90      0.86      1557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic model metrices\n",
    "Basic = ModelBasicMetrices(strings_plain, strings_check)\n",
    "print(Basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2454275"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train strings upload\n",
    "File_train = open(\"PunctuationTask_train.txt\",\"r\")\n",
    "\n",
    "strings_train = File_train.read().replace('\\n', '')\n",
    "strings_train_tokens = np.array(token(strings_train))\n",
    "N = len(strings_train_tokens)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gram(token1, token2, token3):\n",
    "    inds = [i+3 for i in range(N-3) if (strings_train_tokens[i:i+3] == [token1, token2, token3]).all()]\n",
    "    stats = []\n",
    "    len_inds = len(inds) \n",
    "    if len_inds > 0:\n",
    "        for char in chars:\n",
    "            stats.append(list(strings_train_tokens[inds]).count(char))\n",
    "        if len_inds - sum(stats) > max(stats):\n",
    "            recomendation = ''\n",
    "        else:\n",
    "            recomendation = chars[np.argmax(stats)]\n",
    "    else:\n",
    "        recomendation = ''\n",
    "    return recomendation\n",
    "\n",
    "def untocken(tockens):\n",
    "    string = tockens[0]\n",
    "    for tocken in tockens[1:]:\n",
    "        if tocken in chars:\n",
    "            string = string + tocken\n",
    "        else:\n",
    "            string = string + ' ' + tocken\n",
    "    return string\n",
    "\n",
    "def addPunctuationGram(string):\n",
    "    token_string = token(string)\n",
    "    i = 0\n",
    "    while i < len(token_string) - 2:\n",
    "        recomendation = check_gram(token_string[i], token_string[i+1], token_string[i+2])\n",
    "        if len(recomendation) > 0:\n",
    "            token_string.insert(i+3, recomendation)\n",
    "        i += 1\n",
    "    untockened_string = untocken(token_string).capitalize()\n",
    "    if not untockened_string.endswith('.'):\n",
    "        untockened_string = untockened_string + '.'\n",
    "    return untockened_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It can be a very complicated thing, the ocean.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "addPunctuationGram('it can be a very complicated thing the ocean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelGramMetrices(strings_plain, strings_check):\n",
    "    return verifyPuntuationMetrics(strings_plain, strings_check, addPunctuationGram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.96      0.99      0.98        82\n",
      "           ,       0.50      0.14      0.22         7\n",
      "           .       0.44      1.00      0.62         4\n",
      "           ;       0.00      0.00      0.00         1\n",
      "           ?       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.91        95\n",
      "   macro avg       0.38      0.43      0.36        95\n",
      "weighted avg       0.89      0.91      0.88        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4-gram model metrices\n",
    "Gram = ModelGramMetrices(strings_plain[:5], strings_check[:5])\n",
    "print(Gram)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
